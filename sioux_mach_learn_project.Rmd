---
output:
  bookdown::pdf_document2:
    includes:
      in_header: latex/preamble.tex
      before_body: latex/titlepage.tex
    pandoc_args:
    - --csl
    - references/apa.csl
  bookdown::html_document2:
    pandoc_args:
    - --csl
    - references/apa.csl
  bookdown::word_document2:
    pandoc_args:
    - --csl
    - references/apa.csl
toc-title: Table of Contents
bibliography: references/references.bib
link-citations: yes
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \renewcommand{\headrulewidth}{0pt}
- \fancyfoot[C]{}
- \fancyfoot[R]{\thepage}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, messages = FALSE)
packages <- c("dplyr","readxl", "curl", "ggplot2", "ggrepel", "maps", "plotly", "stringr", "tm", "wordcloud2", "tidyverse", "RColorBrewer", "ggwordcloud", "viridis", "bookdown", "utils", "leaps", "broom","GGally", "e1071", "caret", "mgcv", "imbalance", "MLmetrics")
package.check <- lapply(packages, FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
        install.packages(x, dependencies = TRUE)
        library(x, character.only = TRUE)
    }
})
```

\fancyhead[LR]{}
\pagenumbering{roman}

\newpage
\cleardoublepage
\pagenumbering{arabic}
\fancyhead[L]{Applied Machine Learning and Predictive Modelling: Stroke Prediction}
\fancyhead[R]{MPM02}


# Introduction
Use case:
We are a smart watch manufacturer working on a new feature for stroke prevention. According to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths. Therefore, our aim is to prevent stoke in future with the help of existing data and machine learning models. 

In the following project we are going to analyze survey data that we plan to ask our users, complementing it with HR (Heart Rate) and CGM (Continuous Glucose Monitoring) data that our product already measures. We hope that our feature can prevent serious health issues and motivate our users to adopt healthier lifestyles.

We worked with a Stroke Prediction Data set from [@https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset].

In the following document, different calculation and models  are used. The different models are intended to reflect both the teaching content from the course and the knowledge that the authors have gained during the learning process itself. 

For the following work, different R packages have been used. The respective packages and their installation can be found in the original R Markdown file or the README. 

!! Hier evtl auch Schwierigkeit von Linear Models beschreiben??

# Importing Data and Change Type of Parameters

The first step was to research the relevant data. The data was imported into R. For simplicity, not all of the code is included. However, all code can be found in the original R Markdown file. 


```{r}
stroke_data <- read_csv('./data/healthcare-dataset-stroke-data.csv')

stroke_data$age <- as.integer(stroke_data$age)
stroke_data$smoking_status <- as.factor(stroke_data$smoking_status)
stroke_data$work_type <- as.factor(stroke_data$work_type)
stroke_data$gender <- as.factor(stroke_data$gender)
stroke_data$ever_married <- as.factor(stroke_data$ever_married)
stroke_data$Residence_type <- as.factor(stroke_data$Residence_type)
stroke_data$stroke_num <- as.numeric(stroke_data$stroke)
stroke_data$stroke <- as.factor(stroke_data$stroke)

stroke_data
```


# Data Cleaning and Exploratory Data Analysis

The data has been prepared for an easier analysis and for fitting the models and calculations.

```{r}
head(stroke_data)
```


```{r}
#rename parameter residence_type to lower case for stylistic purposes
stroke_data <- stroke_data %>% rename("residence_type" = "Residence_type")
```

```{r}
#check for the dimension of the data set
dim(stroke_data)
```

The data set contains 201 missing values in "bmi". 

```{r}
#check for missing values
colSums(is.na(stroke_data))
```

As the data set given is already quite small and the missing values also concern data from people who had a stoke, we will replace the missing values with the mean "bmi" value. 

```{r message=FALSE, warning=FALSE}
#convert bmi as number and replace missing values with the mean value of bmi
stroke_data$bmi <- as.numeric(stroke_data$bmi)
stroke_data$bmi[is.na(stroke_data$bmi)] <- mean(stroke_data$bmi, na.rm = TRUE)
```


## Summaries

In the following chapter, the different variables are summarized by no-stroke (0) and stroke (1). Please note that not all code is included in the PDF, the full code can be found in the rmarkdown. 

```{r}
#comparing gender with stroke
stroke_by_gender = table(stroke_data$gender, stroke_data$stroke)
names(dimnames(stroke_by_gender))<- c("Gender", "Stroke")
stroke_by_gender
```


```{r include=FALSE}
#testing the effect of non smokers and smokers
count_by_smoke_status <- stroke_data %>% 
  select(smoking_status, stroke) %>%
  group_by(smoking_status, stroke) %>%
  summarise( N = n())

```
```{r}
#testing the effect of work type
 count_by_work_type <- stroke_data %>% 
   select(work_type, stroke) %>% 
   group_by(work_type, stroke) %>%
   summarise( N = n())
```
```{r}
 # testing the effects of residence type
count_by_residence_type <- stroke_data %>% 
   select(residence_type, stroke) %>% 
   group_by(residence_type, stroke) %>%
   summarise( N = n())
```
```{r}
 # testing the effects of gender
count_by_gender <- stroke_data %>% 
   select(gender, stroke) %>% 
   group_by(gender, stroke) %>%
   summarise( N = n())

```
```{r}
 # testing the effects of hypertension
count_by_hypertension <- stroke_data %>% 
   select(hypertension, stroke) %>% 
   group_by(hypertension, stroke) %>%
   summarise( N = n())

```
```{r}
# testing the effects of heart disease
count_by_heart_disease <- stroke_data %>% 
   select(heart_disease, stroke) %>% 
   group_by(heart_disease, stroke) %>%
   summarise( N = n())
```
```{r}
# testing the effects of marriage status
count_by_marriage <- stroke_data %>% 
   select(ever_married, stroke) %>% 
   group_by(ever_married, stroke) %>%
   summarise( N = n())
```


## Scatterplots

With the following Scatterplots the strength of the relation between the various parameters should be visualized in more detail. These leads to a better understanding of the data. For the sake of simplicity we do not include all plots, the whole code can be found in the rmarkdown file.


The following scatterplots shows a positive correlation between stroke (1) and age as with stroke (1) and bmi. For bmi there seems to be too many outliers to see a correlation with stroke (1).

```{r}
stroke_data %>% 
  ggplot(mapping = aes(x = bmi, y = age, color = stroke)) +
  geom_point() +
  geom_smooth(method = 'lm')
```


```{r scatterplots, include=FALSE}
stroke_data %>% 
  filter(stroke == 1) %>%
  ggplot(mapping = aes(x = bmi, y = age, color = smoking_status)) +
  geom_point(method = 'lm') +
  geom_smooth(method = 'lm')

stroke_data %>% 
  ggplot(mapping = aes(x = bmi, y = avg_glucose_level, color = stroke)) +
  geom_point() +
  geom_smooth(method = 'lm')

stroke_data %>% 
  filter(stroke == 1) %>%
  ggplot(mapping = aes(x = bmi, y = avg_glucose_level, color = stroke)) +
  geom_point(method = 'lm') +
  geom_smooth(method = 'lm')
```

## Boxplots

With the following Boxplots the distribution of the data points is visualized. Again, not all Boxplots are included. 


```{r boxplot_gluc, include=FALSE}
#Boxplot on avg. glucose_level
ggplot(stroke_data, aes(y = avg_glucose_level)) +
  geom_boxplot()
```

```{r include=FALSE}
#Boxplot on Age 
ggplot(stroke_data, aes(y = age)) +
  geom_boxplot() 
```

The following boxplot visualizes the distribution no-Stroke (0) and Stroke (1) by Age. As we can see the median Age for people suffering a Stroke is higher and is around 76 years old. Also the Distribution besides a few outliers is smaller. 

```{r echo=TRUE}
stroke_by_age <- stroke_data %>%
# dplyr::filter(stroke == 1) %>%
 ggplot(aes(x = stroke,
            y = age)) +
  geom_boxplot(color="orange", fill="yellow", alpha=0.2) +
  ggtitle("Boxplot on noâˆ’Stroke (0) and Stroke (1) by Age") + 
  xlab("Stroke") + ylab("Age") +
  theme_minimal() + theme(axis.text.x = element_text(angle = 0)) 
stroke_by_age 
```



```{r include=FALSE}
#Boxplot on BMI
ggplot(stroke_data, aes(y = bmi)) +
geom_boxplot()
```

In the following the distribution of the bmi by no-Stroke (0) and Stroke (1) is shown. As we can see the Median of the two variables are nearly the same around 26. For the people with no-Stroke (0) the distribution of the bmi is higher. There seems to be a lot of outliers with an high bmi.  

```{r}
stroke_by_bmi <- stroke_data %>%
# dplyr::filter(stroke == 1) %>%
 ggplot(aes(x = stroke,
            y = bmi)) +
  geom_boxplot(color="orange", fill="yellow", alpha=0.2) +
  ggtitle("BMI by Stroke") + 
  xlab("Stroke") + ylab("BMI") +
  theme_minimal() + theme(axis.text.x = element_text(angle = 0))
stroke_by_bmi
```


```{r include=FALSE}
#boxplot by avg_glucose_level and stroke
stroke_by_avg_glucose_level <- stroke_data %>%
# dplyr::filter(stroke == 1) %>%
 ggplot(aes(x = stroke,
            y = avg_glucose_level)) +
  geom_boxplot(color="orange", fill="yellow", alpha=0.2) +
  ggtitle("Average Glucose Level by Stroke") + 
  xlab("Stroke") + ylab("Avg. Glucose Level") +
  theme_minimal() + theme(axis.text.x = element_text(angle = 0))

stroke_by_avg_glucose_level

```


# Methodology

```{r}
set.seed(7406)
n=dim(stroke_data[1])  # number of observations in dataset
n_train=0.70*n  # training set is 70%
flag = sort(sample(1:n, size=n_train, replace=FALSE))
```
```{r}
# Use df (all data points without ID column) df_train, and df_test
# Gender, hypertension, heart disease, ever married, work type, residence type, smoking status, and stroke are all factor types.
# This should allow for the best modeling options possible for our methods.
df_train = stroke_data[flag,]
df_test = stroke_data[-flag,]
```

```{r}
head(df_test)
head(df_train)
```


# Linear Models

```{r}
set.seed(7406)
n=dim(stroke_data[1])  # number of observations in dataset
n_train=0.70*n  # training set is 70%
flag = sort(sample(1:n, size=n_train, replace=FALSE))
```
```{r}
# Use df (all data points without ID column) df_train_linear, and df_test_linear
# Gender, hypertension, heart disease, ever married, work type, residence type, smoking status, and stroke are all factor types.
# This should allow for the best modeling options possible for our methods.
df_train_linear = stroke_data[flag,]
df_test_linear = stroke_data[-flag,]
```

```{r}
head(df_test_linear)
head(df_train_linear)
```

Our aim is to predict strokes, and the stroke variable is always our response variable of interest in this use case. However, simple or multiple linear regression is not the tool of choice, as stroke is a binary response variable. 
Thus in the following we will nonetheless fit a linear regression model to our data with stroke as the response variable. However, out of all the linear methods, we will only focus on on a binomial model with family set to "binomial" in greater detail.

## Selecting Predictors for the model

Apart from testing out individual variables, we also tested a model with all predictors to find out about the significant ones, as selecting all variables may not necessarily lead to a more accurate model, and we might run into overfitting problems. Furthermore, our variable selection is also informed by our exploratory plots above, and what we intuitively believe to be accurate risk factors for a stroke.

```{r}
# fitting models for simple regression model
lm.stroke.test <- lm(stroke_num ~ ., data = df_train_linear)
summary(lm.stroke.test)
```
Out of the significant predictors above, we chose the following model for the linear model, glm, and gam:


```{r}
# fitting models for simple regression model
linear_model <- stroke_num ~ age + hypertension + heart_disease + avg_glucose_level
```

Although ever_married theoretically returns a significant result, this is most probably confounded by age, as can be seen in the plot below, the subjects that are or were married at some point tend to be significantly older than those that have never married.
The same is most likely true for the work type, with those having never worked being younger. What surprised us, though, is that smoking status did not have as big of an effect as we would have anticipated. 

```{r}
# fitting models for simple regression model
lm.married <- lm(age ~ ever_married, data = df_train_linear)
summary(lm.married)
 
plot(age ~ ever_married, data = df_train_linear)
abline(lm.married)
```


```{r}
# fitting models for simple regression model
lm.stroke <- lm(stroke_num ~ age + hypertension + heart_disease * avg_glucose_level, data = df_train_linear)
summary(lm.stroke)
 
plot(stroke_num ~ age + hypertension + heart_disease + avg_glucose_level, data = df_train_linear)
abline(lm.stroke)
```
Next, we evaluate the model fit with a confusion matrix. In the first example, we have constructed one "manually". 
In all further examples we will be using the caret package's confusionMatrix() function.

```{r}
# Evaluating model fit using predict linear regression, example of a self-constructed confusion matrix

predicted.lm.stroke <- ifelse(predict(lm.stroke, df_test_linear, type = "response") < 0.15, yes = 0, no = 1)
head(predicted.lm.stroke)

obs.predicted.comp.lm <- data.frame(obs = df_test_linear$stroke_num, predicted = predicted.lm.stroke)

table(obs = obs.predicted.comp.lm$obs, fit = obs.predicted.comp.lm$predicted)

table(obs = obs.predicted.comp.lm$obs, fit = obs.predicted.comp.lm$predicted) %>%
  prop.table() %>%
  round(digits = 2)
```

```{r}
# Evaluating model fit using predict linear regression using confusionMatrix()

predicted.lm.stroke <- ifelse(predict(lm.stroke, df_test_linear, type = "response") < 0.15, yes = 0, no = 1)
head(predicted.lm.stroke)

confusionMatrix(as.factor(predicted.lm.stroke), as.factor(df_test_linear$stroke))
```


# Generalised Linear Model with family set to Poisson

```{r}
# text
glm.stroke.poisson <- glm(stroke_num ~ age + heart_disease + hypertension + avg_glucose_level,
family = "poisson",
data = df_train_linear)
summary(glm.stroke.poisson)
#plot(stroke_num ~ age + heart_disease + hypertension + avg_glucose_level, data = df_train_linear)
#abline(glm.stroke_poisson)
ggplot(data = df_train_linear, aes(x = avg_glucose_level, y = stroke_num)) + 
  geom_jitter(width = 0, height = 0.05) +
  geom_smooth(method = "glm", method.args = list(family = "poisson"))

```

Below is comparison of the fitted values versus the actual observed values within the training data set.

```{r}
# Evaluating model fit poisson

# fitted(glm.stroke.poisson)
fitted.glm.stroke.poisson <- ifelse(fitted(glm.stroke.poisson) < 0.2, yes = 0, no = 1)
head(fitted.glm.stroke.poisson)

obs.fitted.comp.poisson <- data.frame(obs = df_train_linear$stroke_num, fitted = fitted.glm.stroke.poisson)

table(obs = obs.fitted.comp.poisson$obs, fit = obs.fitted.comp.poisson$fitted)

table(obs = obs.fitted.comp.poisson$obs, fit = obs.fitted.comp.poisson$fitted) %>%
  prop.table() %>%
  round(digits = 2)
```

```{r}
# Evaluating model fit using predict linear regression using confusionMatrix()

glm.stroke.poisson.prediction <- as.factor(ifelse(predict(glm.stroke.poisson, df_test_linear, type = "response") < 0.15, yes = 0, no = 1))
head(glm.stroke.poisson.prediction)

confusionMatrix(glm.stroke.poisson.prediction, df_test_linear$stroke)
```


# Generalised Linear Model with family set to Binomial
Since we are essentially dealing with a classification issue, using logistic regression in the form of a GLM with family set to "binomial" is the best method to apply out of all the models introduced so far. For this reason, we shall go into more detail here.

```{r}
# Include all variables to start variable selection
# Plot all of them for visual analysis
glm.stroke.binomial <- glm(stroke ~ age + gender + avg_glucose_level + residence_type + work_type + heart_disease + hypertension + ever_married + bmi + smoking_status,
family = "binomial",
data = df_train_linear)
summary(glm.stroke.binomial)
```

```{r}
prediction.glm <- predict(glm.stroke.binomial, df_test_linear, type = "response")
# InformationValue::optimalCutoff(df_test_linear, prediction.glm)

str(prediction.glm)
```

```{r}
predicted.glm.stroke.binomial <- as.factor(ifelse(predict(glm.stroke.binomial, df_test_linear, type = "response") < 0.15, yes = 0, no = 1))
head(predicted.glm.stroke.binomial)

confusionMatrix(predicted.glm.stroke.binomial, df_test_linear$stroke)
```


```{r}
# First iteration with parameters chosen from intuitive domain knowledge and exploratory analysis of data
glm.stroke.binomial <- glm(stroke ~ age + heart_disease + hypertension + work_type + avg_glucose_level + smoking_status,
family = "binomial",
data = df_train_linear)
summary(glm.stroke.binomial)
#plot(stroke ~ age + heart_disease + hypertension + work_type + avg_glucose_level + smoking_status, data = df_train_linear)
#abline(glm.stroke.binomial)
```
```{r}
# second iteration only keeping statistically relevant parameters from previous model
glm.stroke.binomial.2 <- glm(stroke_num ~ age + heart_disease + hypertension + avg_glucose_level,
family = "binomial",
data = df_train_linear)
summary(glm.stroke.binomial.2)
# plot(stroke ~ age + heart_disease + hypertension + avg_glucose_level, data = df_train_linear)
# abline(glm.stroke.binomial.2)

pred <- predict(glm.stroke.binomial.2)
# pred

ggplot(data = df_train_linear, aes(x = age, y = stroke_num)) + 
  geom_jitter(width = 0, height = 0.05) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"))

```
```{r}
predicted.glm.stroke.binomial.2 <- as.factor(ifelse(predict(glm.stroke.binomial.2, df_test_linear, type = "response") < 0.2, yes = 0, no = 1))
head(predicted.glm.stroke.binomial.2)

# predicted.glm.stroke.binomial.2 <- as.factor(predicted.glm.stroke.binomial.2)
# predicted.glm.stroke.binomial.2 <- relevel(predicted.glm.stroke.binomial.2, "0")

confusionMatrix(predicted.glm.stroke.binomial.2, df_test_linear$stroke)
```



# Generalised Additive Model
```{r}
library(mgcv)

gam.stroke <- gam(stroke_num ~ age + heart_disease + hypertension + avg_glucose_level,
family = "binomial",
data = df_train_linear)
summary(gam.stroke)
#plot(stroke ~ smoking_status, data = df_train_linear)
#abline(gam.stroke)

```


```{r}
predicted.gam.stroke <- as.factor(ifelse(predict( gam.stroke, df_test_linear, type = "response") < 0.2, yes = 0, no = 1))
head(predicted.gam.stroke)

confusionMatrix(predicted.gam.stroke, df_test_linear$stroke)
```



# Neural Network Yves 

```{r}
# read the csv agein, because the data needs to be idfferently prepared than in other model
stroke_data_nn <- read_csv('./data/healthcare-dataset-stroke-data.csv')

```

```{r}
# have a look at the data -> it is discovered, that bmi is not numeric, let's change that
str(stroke_data_nn)

stroke_data_nn[10] <- sapply(stroke_data_nn[10], as.numeric)

str(stroke_data_nn)

#install.packages("caret")
```

```{r}
# make a df with only numeric values
#numeric_var_original_scale <- stroke_data_nn %>% select(where(is.numeric) & !where(is.integer))

#cat_var <- stroke_data_nn[,!(names(stroke_data_nn) %in% names(numeric_var_original_scale))] %>% select(-stroke)

#target_var= (stroke_data_nn %>% select(stroke)) %>% 
#  mutate(stroke=as.factor(ifelse(stroke==0, "no_stroke","stroke" )))
```

```{r}
# have a look at the structure of each df
#str(numeric_var)
#str(cat_var)
#str(target_var)
```

```{r}
#get parameters of center scale to use in train and unseen data with caret library

#library(caret)

#preproc.param_comp <- numeric_var_original_scale  %>% preProcess(method = c("center", "scale"))

#numeric_var <- preproc.param_comp %>% predict(numeric_var_original_scale)

#predictors_var= cbind.data.frame(cat_var,numeric_var)

```

```{r}
#now we have:
#head(target_var)
```

```{r}
#NA values are already solved, so lets see if some predictors have small variances:
# Identify near zero variance predictors: remove_cols

#remove_cols <- nearZeroVar(numeric_var, names = TRUE, 
#                           freqCut = 10, uniqueCut = 20)

#remove_cols
```

```{r}
#lets see if some predictor have some high leverage point
#plot(numeric_var)
```

```{r}
#it's ok for me, lets see correlation between variables matrix
#numeric_varcor = numeric_var_original_scale
#names(numeric_varcor) = c("Age", "Avg. glucose level", "BMI")

#correlationMatrix1 <- round(cor(numeric_varcor),2) 

```

```{r}
#highlyCorrelated <- findCorrelation(correlationMatrix1, cutoff=0.75) #useful for large matrices

#print(highlyCorrelated)
```

```{r}
#library(GGally)

#corplot1 = ggpairs(numeric_varcor,diag=list(continuous= wrap("densityDiag",fill="palegreen1")),
#                   lower= list(continuous = wrap("points", color = "red", alpha = 0.5)))+theme_bw()

#full_data = cbind.data.frame(target_var, predictors_var)

#70-30
#train.index <- createDataPartition(target_var$stroke, p = 0.7, list = FALSE)

#train_data_imb <- full_data[ train.index,]

#test_data0 <- full_data[-train.index,]

#dim(train_data_imb)

#dim(test_data0)
```

```{r}
#Let's upsampling to balance the data 

#dummycar <- dummyVars(" ~ .", data=train_data_imb %>% select(-stroke))
#train dummies
#train_data_imb_dummy <- cbind.data.frame(stroke= train_data_imb %>% select(stroke), 
#                                         predict(dummycar, newdata = train_data_imb %>% select(-stroke)))

#names(train_data_imb_dummy) <- make.names(names(train_data_imb_dummy), unique=TRUE)

#test dummies
#test_data <- cbind.data.frame(stroke= test_data0 %>% select(stroke), 
#                              predict(dummycar, newdata = test_data0 %>% #select(-stroke)))

#names(test_data) <- make.names(names(test_data), unique=TRUE)

#install.packages("imbalance")
#library(imbalance)
#print("Before upsampling")
#table(train_data_imb_dummy$stroke)

#numInst= table(train_data_imb_dummy$stroke)[1]-table(train_data_imb_dummy$stroke)[2]

#mwmote1 <- mwmote(train_data_imb_dummy, numInstances = numInst,classAttr="stroke")
```

```{r}
#I will set the decimals in the categories to 0 or 1, otherwise the variables would be treated as continuous
#mwmote2=mwmote1 %>% select(-c(stroke,age,avg_glucose_level,bmi)) %>% 
 # apply(2,  FUN=function(x) ifelse(x > 0.5, 1, 0) )

#mwmote3=cbind.data.frame(stroke=mwmote1[["stroke"]], mwmote2 ,
 #                        mwmote1 %>% select(age,avg_glucose_level,bmi ))

#train_data=rbind.data.frame(train_data_imb_dummy, mwmote3)

#print("After upsampling")
#table(train_data$stroke)


#tune_grid_nnet= expand.grid(size = seq(from = 39, to = 42, by = 1), decay = c(0,0.1,0.5))
```

```{r}
#Create custom trainControl

myControl <- trainControl(
  method = "repeatedcv", 
  number = 10,repeats=3,
  summaryFunction = prSummary, #to include F1 score
  classProbs = TRUE, search = "grid", 
  verboseIter = TRUE, savePredictions =TRUE)

```

```{r}
# let's train the model -> can the up to 3 hours depending on your procesor
#install.packages('MLmetrics')

#nnet_model <- train(
#  stroke~.,
#  data=train_data,
#  method = "nnet",metric="F",
#  trControl = myControl,
#  tuneGrid = tune_grid_nnet	)
```

```{r}
#lets have a look at the outcome
#nnet_model
```

```{r}
#lets check to confusion matrix on test data
#prediction_nnet0= predict(nnet_model, test_data, type="prob")
#dim(prediction_nnet0)
```

```{r}
# If p exceeds threshold of 0.5
#thresh_nnet = ifelse(prediction_nnet0[,"stroke"] > 0.5, "stroke","no_stroke")
```

```{r}
# Convert to factor
#p_class_nnet =as.factor(thresh_nnet)
```

```{r}
# Create confusion matrix# as the matrix shows -> the model could reach an accuracy of 94.97% in previous runs
#conf_matrix_nnet= confusionMatrix(p_class_nnet , test_data[["stroke"]],positive = "stroke",mode = "everything")
#conf_matrix_nnet
```





################################




# Support Vector Machine (Larissa)

Stroke Data Classification using a Support Vector Machine. In the following two different approaches for the Stroke Data Classification are used. On one hand to compare the different approaches and on the other hand for the learning purpose. 

In the following model "svm_linear" the SVM model is implemented with the caret package. Our target variable is the stroke parameter which contains 0 (no-stroke) and 1 (stroke) which we want to predict. The first step is to split the data set into training and testing data. The training data is used for building the model and the testing data for evaluating the model.

```{r}
head(stroke_data)
```

As we need different data types and have to remove the gender "other" data point for an optimal performance of the SVM model, we create a need data set variable in the following. 

```{r}
#define new data set
svm_stroke <- stroke_data
head(svm_stroke)
```


```{r}
#replace gender "Other" with "Female
svm_stroke[svm_stroke == "Other"] <- "Female"
```



```{r}
#set numeric stoke data type to NUll
svm_stroke$stroke_num <- NULL
head(svm_stroke)
```



```{r}
#split the data into test and train data with a split of 70 (training) / 30 (testing)
set.seed(7406)
intrain <- createDataPartition(y = svm_stroke$stroke, p = 0.7, list = FALSE)   #selecting our target variable "stroke"
training <- svm_stroke[intrain, ]
testing <- svm_stroke[-intrain, ]

```

```{r}
#checking the dimension of the training and testing data set
dim(training)
dim(testing)
```

Implement the trainControl Method. This function will control the computation overheads which allow us to use the train function which is implemented by the caret package. In the following we use the trainControl function with the repeated cross-validation method, with a iteration of 10 and with repeates set to 3 to compute the repeated cross-validation 3 times.

```{r}
#implement the train control method with the repeated cross-validation method, 
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
```

In the following we pass the trainControl function to our training method. In the train function we pass our target variable stroke and set the method to linear. The following output shows our train method. As our model was trained with the C value as one we now can predict our testing data set. 

```{r message=FALSE, warning=FALSE}
#implement the train function from caret
svm_linear <- train(stroke ~., data = training, method = "svmLinear",
                    trControl=trctrl,
                    prepProcess = c("center", "scale"),
                    tuneLenght = 10)
svm_linear
```

When running our testing model we will get the prediction values with 0 (no-stroke) and 1 (stroke). In the following we use the predict function and pass the trained model and as new data we pass the testing data.

```{r echo=T, results='hide'}
#test predict with testing data
test_pred <- predict(svm_linear, newdata = testing)
test_pred
```

In the next step we are going to test the accuracy of our model. We do this with the help of the confusionMatrix. The following output shows, that our model has an accuracy of 94%. Which seems to be quite good. However for the sake of completeness, we going to improve our model with customizing cost values and the crossvalidation method. 

```{r}
#testing the accuracy of our model with confusionMatrix
confusionMatrix(table(test_pred, testing$stroke))
```


```{r}
#define different values for c
grid <- expand.grid(C = c(0, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2.5))
```

The following output shows that the model shows the final value used for the model was C = 0.01.

```{r message=FALSE, warning=FALSE}
#improving the performance
svm_linear_grid <- train(stroke ~., data = training, method = "svmLinear",
                         trControl=trctrl,
                         preProcess = c("center", "scale"),
                         tuneGrid = grid,
                         tuneLength = 10)

svm_linear_grid
```


```{r}
test_pred_grid <- predict(svm_linear_grid, newdata = testing)
test_pred_grid 
```

With the new test_pred_grid we can achieve an Accuracy of 95% which meand we could improve our model about 1%. 

```{r}
confusionMatrix(table(test_pred_grid, testing$stroke))
```

\newpage

In the following the second approach for the SVM Model is presented. In a first step we again split the data set into training and testing data sets.


```{r}
#create train and test data set for SVM Model with a split 70 (training) / 30 (test) 
set.seed(7406)
n=dim(svm_stroke[1])  # number of observations in dataset
n_train=0.70*n  # training set is 70%
flag = sort(sample(1:n, size=n_train, replace=FALSE))
```

```{r}
#use all parameters without first column id
df_train_svm = svm_stroke[flag,]
df_test_svm = svm_stroke[-flag,]
```


```{r}
#define stroke train and test variables
ytrain = df_train_svm$stroke
ytest = df_test_svm$stroke
```
 
```{r}
table(df_train_svm$stroke)
```

```{r}
summary(df_train)
summary(df_test)
```

In the following SVM Model we set the kernel to radial and cost to 5. In the following the SVM Classification Plot is shown. It seems that Age is the bigger influence on having a stroke or not compared to the BMI. 

```{r}
#setup our svm model with kernel set to radial
svm_model_radial <- svm(stroke ~. , data = df_train_svm, type = "C-classification", kernel = "radial", cost = 5)
summary(svm_model_radial)
plot(svm_model_radial, data = df_train_svm, bmi ~ age, slice = list(avg_glucose_level = 3))
```



In the following we checked the model fit with a confusion matrix with the help of the caret package's confusionMatrix() function. The following output shows an Accuracy of 94% again. It seems that we receive the same results for the linear and the radial approach. 

```{r}
#confusion matrix for training error
svm_training_prediction <- predict(svm_model_radial, newdata = df_train_svm)
svm_training_error <- mean(svm_training_prediction != ytrain)
confusionMatrix(svm_training_prediction, df_train_svm$stroke)
svm_training_error
confusionMatrix(svm_training_prediction,df_train_svm$stroke)
```


```{r}
#confusion matrix for test data
svm_prediction <- predict(svm_model_radial, newdata = df_test_svm)
svm_test_error <- mean(svm_prediction != ytest)
confusionMatrix(svm_prediction,df_test_svm$stroke)
svm_test_error
```

In the following we tune the parameters for the SVM while changing C.
```{r}
#tune parameters for svm
set.seed(123)
tuned_svm <- tune(svm, stroke ~ . , data = df_train_svm, ranges = list(epsilon = seq(0, 1, 0.1), cost = 2^(2:5)))
tuned_svm
```
In the following plot we see the Performance of the SVM. The darker the colour, the lower the misclassification error. Therefore, we can say, the lower values and epsilon works best for our model. 

```{r}
plot(tuned_svm)
summary(tuned_svm)
```

Now, lets choose the best model for our Data. 

```{r}
#choose the best model based on hyperparameter 
svm_after_tuned <- tuned_svm$best.model
summary(svm_after_tuned)
```

```{r}
#plot the tuned SVM model
plot(svm_after_tuned, data = df_train_svm, bmi ~ age, slice = list(avg_glucose_level = 3))
```


Again, we checked the Accuracy of the model after tuning the hyperparameters with the help of the confusion matrix. As we can see, the model receives an accuracy of 95%. Again, we receive the same results with the radial kernel as we did with the linear kernel.

```{r}
# Confusion matrix after tuning hyperparameters
svm_prediction_tuned <- predict(svm_after_tuned, newdata = df_test_svm)
svm_tuned_test_error <- mean(svm_prediction_tuned != ytest)
confusionMatrix(svm_prediction_tuned,df_test_svm$stroke)
svm_tuned_test_error
```

```{r}
#compare the tuned prediction with the test data 
confusionMatrix(svm_prediction_tuned,df_test_svm$stroke)
```


# Conclusion

\newpage
